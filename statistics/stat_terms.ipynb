{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIFFERENT STATISTICAL TERMENOLOGIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **ANOVA** stands for **Analysis of Variance**. It's a statistical test that was developed by **Ronald Fisher** in **1918**. ANOVA tells you if there are any statistical differences between the means of three or more independent groups. One-way ANOVA is the most basic form.ANOVA helps you find out whether the **differences between groups of data are statistically significant**. It works by analyzing the levels of variance within the groups through samples taken from each of them. it gives a **probability (p-vaue)** of whether or not differences between your groups are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.1</td>\n",
       "      <td>77.75</td>\n",
       "      <td>1.1</td>\n",
       "      <td>39343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.3</td>\n",
       "      <td>78.25</td>\n",
       "      <td>1.3</td>\n",
       "      <td>46205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.5</td>\n",
       "      <td>78.75</td>\n",
       "      <td>1.5</td>\n",
       "      <td>37731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.2</td>\n",
       "      <td>80.50</td>\n",
       "      <td>2.2</td>\n",
       "      <td>39891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  distance  YearsExperience  Salary\n",
       "0  31.1     77.75              1.1   39343\n",
       "1  31.3     78.25              1.3   46205\n",
       "2  31.5     78.75              1.5   37731\n",
       "3  32.0     80.00              2.0   43525\n",
       "4  32.2     80.50              2.2   39891"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "mydata= pd.read_csv(\"ml_data_salary.csv\")\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat=230.458, p=0.000\n",
      "Probably different distributions\n"
     ]
    }
   ],
   "source": [
    "#Example of Analysis of variance test (ANOVA)\n",
    "from scipy.stats import f_oneway\n",
    "data1 = mydata['Salary']\n",
    "data2 = mydata['YearsExperience']\n",
    "data3 = mydata['age']\n",
    "stat, p = f_oneway(data1, data2, data3)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "  print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Analysis of covariance (ANCOVA)** is a general linear model which **blends ANOVA and regression**.Analysis of covariance is used to test the main and interaction effects of categorical variables on a continuous dependent variable, controlling for the effects of selected other continuous variables, which co-vary with the dependent. The control variables are called the \"covariates.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pingouinNote: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Azka\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached pingouin-0.5.1.tar.gz (183 kB)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (1.22.1)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (1.7.3)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (1.4.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (3.5.1)\n",
      "Requirement already satisfied: seaborn>=0.11 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (0.11.2)\n",
      "Collecting statsmodels>=0.13\n",
      "  Downloading statsmodels-0.13.2-cp310-cp310-win_amd64.whl (9.1 MB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pingouin) (1.0.2)\n",
      "Collecting pandas_flavor>=0.2.0\n",
      "  Downloading pandas_flavor-0.2.0-py2.py3-none-any.whl (6.6 kB)\n",
      "Collecting outdated\n",
      "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (4.29.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (9.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0->pingouin) (2021.3)\n",
      "Collecting xarray\n",
      "  Downloading xarray-2022.3.0-py3-none-any.whl (870 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.2->pingouin) (1.16.0)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.2-py2.py3-none-any.whl (233 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting littleutils\n",
      "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->pingouin) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\azka\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->pingouin) (1.1.0)\n",
      "Using legacy 'setup.py install' for pingouin, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for littleutils, since package 'wheel' is not installed.\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, xarray, requests, patsy, littleutils, tabulate, statsmodels, pandas-flavor, outdated, pingouin\n",
      "    Running setup.py install for littleutils: started\n",
      "    Running setup.py install for littleutils: finished with status 'done'\n",
      "    Running setup.py install for pingouin: started\n",
      "    Running setup.py install for pingouin: finished with status 'done'\n",
      "Successfully installed certifi-2021.10.8 charset-normalizer-2.0.12 idna-3.3 littleutils-0.2.2 outdated-0.2.1 pandas-flavor-0.2.0 patsy-0.5.2 pingouin-0.5.1 requests-2.27.1 statsmodels-0.13.2 tabulate-0.8.9 urllib3-1.26.9 xarray-2022.3.0\n"
     ]
    }
   ],
   "source": [
    "pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pingouin import ancova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "\n",
    "#load data\n",
    "df= sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>SS</th>\n",
       "      <th>DF</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>np2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>7.576996e+04</td>\n",
       "      <td>1</td>\n",
       "      <td>28.316695</td>\n",
       "      <td>1.381982e-07</td>\n",
       "      <td>0.038301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>2.586445e+04</td>\n",
       "      <td>1</td>\n",
       "      <td>9.666043</td>\n",
       "      <td>1.951945e-03</td>\n",
       "      <td>0.013413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Residual</td>\n",
       "      <td>1.902497e+06</td>\n",
       "      <td>711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Source            SS   DF          F         p-unc       np2\n",
       "0       sex  7.576996e+04    1  28.316695  1.381982e-07  0.038301\n",
       "1       age  2.586445e+04    1   9.666043  1.951945e-03  0.013413\n",
       "2  Residual  1.902497e+06  711        NaN           NaN       NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform ANCOVA\n",
    "ancova(data=df, dv='fare', covar='age', between='sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANCOVA summary:\n",
    "‘Source’: Names of the factor considered\n",
    "‘SS’: Sums of squares\n",
    "‘DF’: Degrees of freedom\n",
    "‘F’: F-values\n",
    "‘p-unc’: Uncorrected p-values\n",
    "‘np2’: Partial eta-squared\n",
    "RESULT:\n",
    "No significant relationship between age and fare on the basis of sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **MANOVA** is a technique which determines the **effects of independent categorical variables on multiple continuous dependent variables**. It is usually used to compare several groups with respect to multiple continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Multivariate linear model\n",
      "==============================================================\n",
      "                                                              \n",
      "--------------------------------------------------------------\n",
      "       Intercept        Value  Num DF  Den DF  F Value  Pr > F\n",
      "--------------------------------------------------------------\n",
      "          Wilks' lambda 0.3935 2.0000 711.0000 547.8547 0.0000\n",
      "         Pillai's trace 0.6065 2.0000 711.0000 547.8547 0.0000\n",
      " Hotelling-Lawley trace 1.5411 2.0000 711.0000 547.8547 0.0000\n",
      "    Roy's greatest root 1.5411 2.0000 711.0000 547.8547 0.0000\n",
      "--------------------------------------------------------------\n",
      "                                                              \n",
      "--------------------------------------------------------------\n",
      "           sex           Value  Num DF  Den DF  F Value Pr > F\n",
      "--------------------------------------------------------------\n",
      "           Wilks' lambda 0.9533 2.0000 711.0000 17.4012 0.0000\n",
      "          Pillai's trace 0.0467 2.0000 711.0000 17.4012 0.0000\n",
      "  Hotelling-Lawley trace 0.0489 2.0000 711.0000 17.4012 0.0000\n",
      "     Roy's greatest root 0.0489 2.0000 711.0000 17.4012 0.0000\n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.multivariate.manova import MANOVA\n",
    "fit = MANOVA.from_formula('fare + age ~ sex', data=df)\n",
    "print(fit.mv_test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pillai’s Trace test statistics is statistically significant [Pillai’s Trace = 0.0467 F(2.0000 711.0000) 17.4012 p < 0.001] and indicates that sex has a statistically significant association with both age and fare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Multivariate Analysis of Covariance (MANCOVA)** In MANCOVA, we assess for statistical differences on multiple continuous dependent variables by an independent grouping variable, while controlling for a third variable called the covariate; multiple covariates can be used, depending on the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Variance** is a measure of how far a set of data are dispersed out from their mean or average value. It is denoted as ‘σ2’. It is always non-negative and Variance always has squared units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azka\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3755: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return var(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "survived         0.236506\n",
       "pclass           0.698231\n",
       "age            210.723580\n",
       "sibsp            1.214678\n",
       "parch            0.648999\n",
       "fare          2466.665312\n",
       "adult_male       0.239454\n",
       "alone            0.239454\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Standard Deviation** is the spread of statistical data is measured by the standard deviation. Distribution measures the deviation of data from its mean or average position. The degree of dispersion is computed by the method of estimating the deviation of data points. It is denoted by the symbol, ‘σ’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Azka\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3613: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "survived       0.486319\n",
       "pclass         0.835602\n",
       "age           14.516321\n",
       "sibsp          1.102124\n",
       "parch          0.805605\n",
       "fare          49.665534\n",
       "adult_male     0.489340\n",
       "alone          0.489340\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Difference between two;\n",
    "> \n",
    "> Variance is equal to the average squared deviations from the mean, while standard deviation is the number’s square root. Also, the standard deviation is a square root of variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. The **standard error** is a statistical term that measures the accuracy with which a sample distribution represents a population by using standard deviation. In statistics, a sample mean deviates from the actual mean of a population; this deviation is the standard error of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The standard deviation (SD) measures the amount of variability, or dispersion, from the individual data values to the mean, while the standard error of the mean (SEM) measures how far the sample mean (average) of the data is likely to be from the true population mean. The SEM is always smaller than the SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sem(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation (SD) measures the dispersion of a dataset relative to its mean.\n",
    "The standard error of the mean (SEM) measures how much discrepancy is likely in a sample’s mean compared with the population mean.\n",
    "**The SEM takes the SD and divides it by the square root of the sample size**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](stdse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Covariance** is a statistical tool that is used to determine the relationship between the movements of two random variables. When two stocks tend to move together, they are seen as having a positive covariance; when they move inversely, the covariance is negative. **Covariance provides the a measure of strength of correlation between two variable or more set of variables**.\n",
    "9. A **covariate** is thus a possible predictive or explanatory variable of the dependent variable. This may be the reason that in regression analyses, independent variables (i.e., the regressors) are sometimes called covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[          nan           nan]\n",
      " [          nan 2469.43684574]]\n"
     ]
    }
   ],
   "source": [
    "X = df['age']\n",
    "Y = df['fare']\n",
    "c = np.cov(X,Y, rowvar = True)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.cov function returns you a covariance matrix, where off-diagonal entries are covariances and diagonal entries are variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **Univariate** statistics summarize only one variable at a time. Bivariate statistics compare two variables.\n",
    "\n",
    "11. **Multivariate** statistics compare more than two variables. Most multivariate analysis involves a dependent variable and multiple independent variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "12. A **confidence interval** is how much uncertainty there is with any particular statistic. Confidence intervals are often used with a margin of error. It tells you how confident you can be that the results from a poll or survey reflect what you would expect to find if it were possible to survey the entire population. Confidence intervals are intrinsically connected to confidence levels.\n",
    "Confidence levels are expressed as a percentage. Confidence intervals are your results and they are usually numbers.\n",
    "You can find the upper and lower bounds of the confidence interval by adding and subtracting the margin of error from the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](Cl.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. **Alpha** is a threshold value used to judge whether a test statistic is statistically significant. It is chosen by the researcher. Alpha represents an acceptable probability of a Type I error in a statistical test. Because alpha corresponds to a probability, it can range from 0 to 1. In practice, 0.01, 0.05, and 0.1 are the most commonly used values for alpha, representing a 1%, 5%, and 10% chance of a Type I error occurring"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d69e6d194a9951b421559ac9f165de68eeed9895d5d287c2d9854b2dca19775"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
